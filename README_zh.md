<div align="center">

# AgentCPM-GUI 
<!-- è¿™é‡Œæ˜¯å›¾ç‰‡çš„å ä½ç¬¦ï¼Œåç»­éœ€è¦è¡¥å……å›¾ç‰‡è·¯å¾„ -->
<!--<img src="./assets/.png" width="300em" ></img> -->

**ç«¯ä¾§å¯ç”¨çš„ è§†è§‰ã€è¯­éŸ³ã€å¤šæ¨¡æ€GUI Agent**

  <strong>ä¸­æ–‡ |
  [English](./README.md)</strong>



 <span style="display: inline-flex; align-items: center; margin-right: 2px;">
   <a href="docs/wechat.md" target="_blank"> å¾®ä¿¡ç¤¾åŒº</a> &nbsp;|
 </span>
  <span style="display: inline-flex; align-items: center; margin-left: 2px;">
   MiniCPM-V <a href="docs/best_practice_summary_zh.md" target="_blank">&nbsp; ğŸ“– æœ€ä½³å®è·µ</a>
 </span>
  
  <p align="center">
  AgentCPM-GUI
 <a href="https://huggingface.co/openbmb/MiniCPM-o-2_6">ğŸ¤—</a> <a href="https://minicpm-omni-webdemo-us.modelbest.cn/"> ğŸ¤–</a>
</p>

</div>

**AgentCPM-GUI** æ˜¯ä»¥MiniCPM-oä¸ºåŸºç¡€æ„å»ºçš„GUI Agentæ¨¡å‹ã€‚æ€»å‚æ•°é‡8Bï¼Œæ¥å—ç”¨æˆ·æŒ‡ä»¤ï¼Œåœ¨æ‰‹æœºä¸Šè‡ªåŠ¨çš„æ‰§è¡Œä»»åŠ¡ã€‚

## æ›´æ–°æ—¥å¿— <!-- omit in toc -->
* [2025.04.28] ğŸš€ğŸš€ğŸš€ æˆ‘ä»¬å¼€æºäº† AgentCPM-GUIï¼Œé¦–æ¬¾ç«¯ä¾§GUI Agentå¤§æ¨¡å‹ï¼Œæ‹¥æœ‰ä¸­æ–‡APPæ“ä½œèƒ½åŠ›ï¼Œå¹¶åŸºäºRFTä¼˜åŒ–æ€è€ƒèƒ½åŠ›ã€‚

## æ€§èƒ½è¯„ä¼°

### å®šä½åŸºå‡†æµ‹è¯•

| Model                   | fun2bbox | text2bbox | bbox2text | average |
|-------------------------|----------|-----------|-----------|---------|
| MiniCPM-Agent           | 55.5     | 56.8      | 49.9      | 54.07   |
| Qwen2.5-VL-7B           | 36.8     | 52.0      | 44.1      | 44.30   |
| Qwen2.5-VL-72B          | 68.2     | 76.9      | 59.1      | 68.07   |
| Intern2.5-VL-8B         | 17.2     | 24.2      | 45.9      | 29.10   |
| Intern2.5-VL-26B        | 14.8     | 16.6      | 36.3      | 22.57   |
| GPT-4o                  | 22.1     | 19.9      | 14.3      | 18.77   |
| GPT-4o with Grounding   | 44.3     | 44.0      | 14.3      | 44.15   |


### æ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•

| Dataset       | Android Control-Low TM | Android Control-Low EM | Android Control-High TM | Android Control-High EM | GUI-Odyssey TM | GUI-Odyssey EM | AITZ TM | AITZ EM | Chinese APP TM | Chinese APP EM |
| ------------- | ---------------------- | ---------------------- | ----------------------- | ----------------------- | -------------- | -------------- | ------- | ------- | -------------- | -------------- |
| **MiniCPM-Agent** | **94.39** | **90.20** | **77.70** | **69.17** | **90.85** | **74.96** | **85.71** | **76.38** | **96.86** | **91.28** |
|Qwen2.5-VL-7B  |92.11|82.12|69.65|57.36|55.33|40.90|73.16|57.58|68.53|48.80|
|UI-TARS-7B     |93.52|88.89|68.53|60.81|78.79|57.33|71.74|55.31|71.01|53.92|
|OS-Genesis     |90.74|74.22|65.92|44.43|11.67|3.63|19.98|8.45|38.10|14.50|
|OS-Atlas       |73.03|67.25|70.36|56.53|91.83|76.76|74.13|58.45|81.53|55.89|
|Aguvis         |93.85|89.40|65.56|54.18|TBD|TBD|35.71|18.99|67.43|38.20|
|OdysseyAgent   |65.10|39.16|58.80|32.74|TBD|73.78|59.17|31.60|67.56|25.44|
|GPT-4o         |-|19.49|-|20.80|-|20.39|70.00|35.30|TBD|TBD|
|Gemini 2.0     |-|28.50|-|60.20|-|3.27|-|-|-|-|
|Claude         |-|19.40|-|12.50|60.90|-|-|-|-|-|

## æ¨ç†
```bash
#å…‹éš†é¡¹ç›®ä»“åº“
git clone https://github.com/Zhong-Zhang/MiniCPM-Agent
# è¿›å…¥é¡¹ç›®ä»“åº“
cd MiniCPM-Agent
# ä¸‹è½½æ¨¡å‹
å¾…å†™
# ç¯å¢ƒé…ç½®
pip install -r requirements.txt
```

### æ™ºèƒ½ä½“ä»»åŠ¡

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from PIL import Image
import json

# 1. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model_path = "model/AgentCPM-GUI"  # æ¨¡å‹è·¯å¾„
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.bfloat16)
model = model.to("cuda:0") 

# 2. æ„é€ è¾“å…¥
instruction = "è¯·ç‚¹å‡»å±å¹•ä¸Šçš„â€˜è®¾ç½®â€™æŒ‰é’®"  # ç¤ºä¾‹æŒ‡ä»¤
image_path = "assets/test.jpg"  # ä½ çš„å›¾ç‰‡è·¯å¾„
image = Image.open(image_path).convert("RGB")

# 3. æ„é€ æ¶ˆæ¯æ ¼å¼
messages = [{
    "role": "user",
    "content": [
        f"<Question>{instruction}</Question>\nå½“å‰å±å¹•æˆªå›¾ï¼š",
        image
    ]
}]

# 4. æ¨ç†
#è¿™é‡Œä¸å¤ªæ¸…æ¥šminicpmçš„system promptç°åœ¨æ˜¯å•¥æ ·ï¼Œå…ˆéšä¾¿ä»è·¯å¾„é‡Œå¯¼ä¸€ä¸ªè¿›æ¥
with open("my_system_prompt.txt", "r", encoding="utf-8") as f:
    system_prompt = f.read()outputs = model.chat(
    image=None,
    msgs=messages,
    system_prompt=system_prompt,
    tokenizer=tokenizer,
    temperature=0.1,
    top_p=0.3,
    n=1,
)

# 5. è¾“å‡ºç»“æœ
print(outputs)
```

### å®šä½ä»»åŠ¡



